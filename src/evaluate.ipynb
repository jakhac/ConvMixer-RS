{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lmdb\n",
    "from bigearthnet_patch_interface.s2_interface import BigEarthNet_S2_Patch\n",
    "from pathlib import Path\n",
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, cat, stack\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import dataset_class as ds_class\n",
    "importlib.reload(ds_class)\n",
    "\n",
    "load_dotenv('./.env')\n",
    "\n",
    "PATH_TO_MODELS = os.environ.get(\"PATH_TO_MODELS\")\n",
    "BEN_LMDB_PATH = os.environ.get(\"BEN_LMDB_PATH\")\n",
    "TEST_CSV_FILE = os.environ.get(\"TEST_CSV\")\n",
    "\n",
    "assert Path(BEN_LMDB_PATH).exists()\n",
    "assert Path(TEST_CSV_FILE).exists()\n",
    "assert Path(PATH_TO_MODELS).exists()\n",
    "assert os.path.isdir(PATH_TO_MODELS)\n",
    "\n",
    "env = lmdb.open(BEN_LMDB_PATH, readonly=True, readahead=False, lock=False)\n",
    "txn = env.begin()\n",
    "cur = txn.cursor()\n",
    "\n",
    "test_ds = ds_class.BenDataset(TEST_CSV_FILE, BEN_LMDB_PATH, size=50)\n",
    "test_loader = DataLoader(test_ds, batch_size=25, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvMixer(\n",
       "  (patch_embedding): Sequential(\n",
       "    (0): Conv2d(10, 256, kernel_size=(7, 7), stride=(7, 7))\n",
       "    (1): GELU()\n",
       "    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (ConvMixerLayers): ModuleList(\n",
       "    (0): ConvMixerLayer(\n",
       "      (depthwise_conv): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(9, 9), stride=(1, 1), padding=same, groups=256)\n",
       "        (1): GELU()\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (pointwise_conv): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): GELU()\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ConvMixerLayer(\n",
       "      (depthwise_conv): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(9, 9), stride=(1, 1), padding=same, groups=256)\n",
       "        (1): GELU()\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (pointwise_conv): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): GELU()\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): ConvMixerLayer(\n",
       "      (depthwise_conv): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(9, 9), stride=(1, 1), padding=same, groups=256)\n",
       "        (1): GELU()\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (pointwise_conv): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): GELU()\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): ConvMixerLayer(\n",
       "      (depthwise_conv): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(9, 9), stride=(1, 1), padding=same, groups=256)\n",
       "        (1): GELU()\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (pointwise_conv): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): GELU()\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): ConvMixerLayer(\n",
       "      (depthwise_conv): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(9, 9), stride=(1, 1), padding=same, groups=256)\n",
       "        (1): GELU()\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (pointwise_conv): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): GELU()\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): ConvMixerLayer(\n",
       "      (depthwise_conv): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(9, 9), stride=(1, 1), padding=same, groups=256)\n",
       "        (1): GELU()\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (pointwise_conv): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): GELU()\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): ConvMixerLayer(\n",
       "      (depthwise_conv): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(9, 9), stride=(1, 1), padding=same, groups=256)\n",
       "        (1): GELU()\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (pointwise_conv): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): GELU()\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): ConvMixerLayer(\n",
       "      (depthwise_conv): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(9, 9), stride=(1, 1), padding=same, groups=256)\n",
       "        (1): GELU()\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (pointwise_conv): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): GELU()\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Linear(in_features=256, out_features=19, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import training_utils as train_utils\n",
    "importlib.reload(train_utils)\n",
    "\n",
    "model_dir = '05-27_1855-ConvMx-256-8'\n",
    "model_name = 'ConvMx-256-8.pt'\n",
    "\n",
    "model = train_utils.load_complete_model(PATH_TO_MODELS + f'/{model_dir}/{model_name}')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc=0.5578947368421054\n"
     ]
    }
   ],
   "source": [
    "acc_sum = 0.0\n",
    "\n",
    "for X, y_true in test_loader:\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs_sig = torch.sigmoid(model(X))\n",
    "        y_pred = torch.round(outputs_sig)\n",
    "        acc_sum += train_utils.get_accuracy_for_batch(y_true, y_pred)\n",
    "\n",
    "        \n",
    "print(f'test_acc={acc_sum / len(test_loader)}')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b54b6ea0bc7318cd0ebe8744a480d71cf9140ba7cd7ca9d510192f235626c224"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
