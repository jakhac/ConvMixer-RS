{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lmdb\n",
    "from bigearthnet_patch_interface.s2_interface import BigEarthNet_S2_Patch\n",
    "from pathlib import Path\n",
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, cat, stack\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Get paths\n",
    "load_dotenv('./.env')\n",
    "\n",
    "BEN_LMDB_PATH = os.environ.get(\"BEN_LMDB_PATH\")\n",
    "\n",
    "TRAIN_CSV_FILE = os.environ.get(\"TRAIN_CSV\")\n",
    "TEST_CSV_FILE = os.environ.get(\"TEST_CSV\")\n",
    "VAL_CSV_FILE = os.environ.get(\"VAL_CSV\")\n",
    "PATH_TO_MODELS = os.environ.get(\"PATH_TO_MODELS\")\n",
    "\n",
    "assert Path(BEN_LMDB_PATH).exists()\n",
    "assert Path(TRAIN_CSV_FILE).exists()\n",
    "assert os.path.isdir(PATH_TO_MODELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = lmdb.open(BEN_LMDB_PATH, readonly=True, readahead=False, lock=False)\n",
    "txn = env.begin()\n",
    "cur = txn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset_class as ds_class\n",
    "importlib.reload(ds_class)\n",
    "\n",
    "val_ds = ds_class.BenDataset(VAL_CSV_FILE, BEN_LMDB_PATH, 2)\n",
    "train_ds = ds_class.BenDataset(TRAIN_CSV_FILE, BEN_LMDB_PATH, 2)\n",
    "\n",
    "val_loader = DataLoader(val_ds, batch_size=16, shuffle=True)\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine hpyerparameters and prepare paths/folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import conv_mixer as conv_mixer\n",
    "import training_utils as train_utils\n",
    "importlib.reload(conv_mixer)\n",
    "\n",
    "# Hyperparameters\n",
    "h = 256\n",
    "depth = 8\n",
    "# kernel_size\n",
    "# patch_size\n",
    "\n",
    "model_name = f'ConvMx-{h}-{depth}'\n",
    "\n",
    "\n",
    "model = conv_mixer.ConvMixer(10, h, depth, n_classes=19)\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime('%m-%d_%H%M')\n",
    "model_dir = timestamp + '-' + model_name\n",
    "\n",
    "assert not os.path.isdir(PATH_TO_MODELS + '/' + model_dir)\n",
    "os.mkdir(PATH_TO_MODELS + '/' + model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(train_utils)\n",
    "\n",
    "n_epochs = 5\n",
    "val_loss_min = np.inf\n",
    "\n",
    "train_loss_hist = []\n",
    "train_acc_hist = []\n",
    "val_loss_hist = []\n",
    "val_acc_hist = []\n",
    "\n",
    "\n",
    "## try catch keyboard interrupt\n",
    "\n",
    "for e in range(n_epochs):\n",
    "    print(f'{e+1:3d}/{n_epochs} : ', end=\"\")\n",
    "\n",
    "    # Inference, backpropagation, weight adjustments\n",
    "    model.train()\n",
    "    train_loss, train_acc = train_utils.train_batch(val_loader, model, optimizer, loss_fn)\n",
    "        \n",
    "    train_loss_hist.append(train_loss)\n",
    "    train_acc_hist.append(train_acc)\n",
    "    \n",
    "    # # Evaluate on validation data\n",
    "    model.eval()\n",
    "    val_loss, val_acc = train_utils.validate_batch(train_loader, model, loss_fn)\n",
    "        \n",
    "    val_loss_hist.append(val_loss)\n",
    "    val_acc_hist.append(val_acc)\n",
    "    \n",
    "    print(f'train_loss={train_loss:.4f}', f'train_acc={train_acc:.4f}', end=\" \")\n",
    "    print(f'val_loss={val_loss:.4f}', f'val_acc={val_acc:.4f}')\n",
    "    \n",
    "    # Save checkpoint model if validation loss improves\n",
    "    if val_loss < val_loss_min:\n",
    "        print(f'val_loss decreased ({val_loss_min:.6f} --> {val_loss:.6f}). Saving model weights ...')\n",
    "\n",
    "        p = PATH_TO_MODELS + f'/{model_dir}/e{e+1}_{model_name}.pt'\n",
    "        train_utils.save_complete_model(p, model)\n",
    "        \n",
    "        val_loss_min = val_loss\n",
    "\n",
    "\n",
    "print('Finished Training')\n",
    "print('Saving final model ...')\n",
    "p = PATH_TO_MODELS + f'/{model_dir}/{model_name}.pt'\n",
    "train_utils.save_complete_model(p, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,4))\n",
    "ax = fig.add_subplot(121)\n",
    "ax.plot(val_loss_hist, label='val')\n",
    "ax.plot(train_loss_hist, label='train')\n",
    "ax.legend(loc=\"upper right\")\n",
    "# ax.set_ylim([0, 1])\n",
    "ax.set_title(\"loss\")\n",
    "ax.set_xlabel(\"epochs\")\n",
    "\n",
    "ax = fig.add_subplot(122)\n",
    "ax.plot(val_acc_hist, label='val')\n",
    "ax.plot(train_acc_hist, label='train')\n",
    "ax.legend(loc=\"lower right\")\n",
    "ax.set_ylim([0, 1])\n",
    "ax.set_title(\"accuracy\")\n",
    "ax.set_xlabel(\"epochs\")\n",
    "\n",
    "plt.savefig(PATH_TO_MODELS +  f'/{model_dir}/{model_name}.pdf')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b54b6ea0bc7318cd0ebe8744a480d71cf9140ba7cd7ca9d510192f235626c224"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
